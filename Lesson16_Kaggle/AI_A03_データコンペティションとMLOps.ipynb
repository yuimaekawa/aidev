{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "MxkgAyk_Z3cw",
        "outputId": "9df9a8ee-6788-4e58-ca2a-f0035b8b7e5a"
      },
      "outputs": [],
      "source": [
        "# wandbのライブラリをimport\n",
        "import wandb\n",
        "\n",
        "# wandbへログイン\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "T5j09gbJt4ef",
        "outputId": "65f1bb6d-11ba-4206-bbae-39c33625bd1e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Pandasのライブラリをインポート\n",
        "import pandas as pd\n",
        "\n",
        "# 学習データを読み込んで変数 train に格納\n",
        "train = pd.read_csv('./train.csv')\n",
        "\n",
        "# 学習データの表示\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ujL81-7Zt_YB",
        "outputId": "50c1e26a-3733-4985-c8f3-a2787592fd94"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Pclass                                          Name     Sex  \\\n",
              "0          892       3                              Kelly, Mr. James    male   \n",
              "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
              "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
              "3          895       3                              Wirz, Mr. Albert    male   \n",
              "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
              "\n",
              "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
              "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
              "1  47.0      1      0   363272   7.0000   NaN        S  \n",
              "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
              "3  27.0      0      0   315154   8.6625   NaN        S  \n",
              "4  22.0      1      1  3101298  12.2875   NaN        S  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# テストデータを読み込んで変数 test に格納\n",
        "test = pd.read_csv('./test.csv')\n",
        "\n",
        "# テストデータの表示\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGtOlL3CuDTL",
        "outputId": "b70af3b6-ee16-44d5-c79e-afef577afae0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(891, 12)\n",
            "(418, 11)\n"
          ]
        }
      ],
      "source": [
        "# 学習データとテストデータ数を確認\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVHsw2NSuOSG",
        "outputId": "b5ff7062-4dcf-42c0-8c40-6dafdc6913fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age            177\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# trainの欠損値の数を調査して、表示する\n",
        "train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvt1JrlquWTM",
        "outputId": "acd33190-d7aa-4052-d08d-7155f5e0f92d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age             86\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             1\n",
              "Cabin          327\n",
              "Embarked         0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# testの欠損値の数を調査して、表示する\n",
        "test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Uw20OT2ouY99"
      },
      "outputs": [],
      "source": [
        "# 新しい空のDataFrameを作成する\n",
        "temp = pd.DataFrame()\n",
        "\n",
        "# 学習データとテストデータのAge列を連結させ、tempにAge列として追加する\n",
        "temp['Age'] = pd.concat([train['Age'], test['Age']])\n",
        "\n",
        "# trainとtestのAge列について、欠損値をtempのAge列の平均値で埋める\n",
        "train['Age'] = train['Age'].fillna(temp['Age'].mean())\n",
        "test['Age'] = test['Age'].fillna(temp['Age'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3wtzW-TvwW2i"
      },
      "outputs": [],
      "source": [
        "# 学習データとテストデータのFare列を連結させ、tempにFare列として追加する\n",
        "temp['Fare'] = pd.concat([train['Fare'], test['Fare']])\n",
        "\n",
        "# testのみに存在するFare列の欠損値をtempのFare列の平均値で埋める\n",
        "test['Fare'] = test['Fare'].fillna(temp['Fare'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SolzB3Dty4z-",
        "outputId": "822037c4-af7c-4310-9545-92af319b16fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embarked\n",
              "S    914\n",
              "C    270\n",
              "Q    123\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 学習データとテストデータのEmbarked列を連結させ、tempにEmbarked列として追加する\n",
        "temp['Embarked'] = pd.concat([train['Embarked'], test['Embarked']])\n",
        "\n",
        "# tempのEmbakedの値を集計する\n",
        "temp['Embarked'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "73XN0dlkzIy6"
      },
      "outputs": [],
      "source": [
        "# trainのみに存在するEmbarked列の欠損値を'S'で埋める\n",
        "train['Embarked'] = train['Embarked'].fillna('S')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "94J9Q9AJz6R6"
      },
      "outputs": [],
      "source": [
        "# trainとtestから、Cabin,Name,Ticket列を削除する\n",
        "train = train.drop(columns=['Cabin', 'Name', 'Ticket'])\n",
        "test = test.drop(columns=['Cabin', 'Name', 'Ticket'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "79UmHv7e3qiO"
      },
      "outputs": [],
      "source": [
        "# trainのSex列とEmbarked列をダミー変数化して、変数train2に格納する\n",
        "train2 = pd.get_dummies(data=train, columns=['Sex', 'Embarked'])\n",
        "\n",
        "# testのSex列とEmbarked列をダミー変数化して、変数test2に格納する\n",
        "test2 = pd.get_dummies(data=test, columns=['Sex', 'Embarked'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-BFWBIvzVoR",
        "outputId": "7de2eda6-72f0-4e1f-baef-cad8377d5b59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PassengerId    0\n",
              "Survived       0\n",
              "Pclass         0\n",
              "Age            0\n",
              "SibSp          0\n",
              "Parch          0\n",
              "Fare           0\n",
              "Sex_female     0\n",
              "Sex_male       0\n",
              "Embarked_C     0\n",
              "Embarked_Q     0\n",
              "Embarked_S     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train2の欠損値の数を調査して、表示する\n",
        "train2.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6zBD3I2zXm9",
        "outputId": "1e91bc6d-76a9-4eae-c190-262a293df661"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PassengerId    0\n",
              "Pclass         0\n",
              "Age            0\n",
              "SibSp          0\n",
              "Parch          0\n",
              "Fare           0\n",
              "Sex_female     0\n",
              "Sex_male       0\n",
              "Embarked_C     0\n",
              "Embarked_Q     0\n",
              "Embarked_S     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test2の欠損値の数を調査して、表示する\n",
        "test2.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkAr5DLf8087",
        "outputId": "b7af2d6b-230e-4116-e0be-5b2ef57b17f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PassengerId      int64\n",
              "Survived         int64\n",
              "Pclass           int64\n",
              "Age            float64\n",
              "SibSp            int64\n",
              "Parch            int64\n",
              "Fare           float64\n",
              "Sex_female        bool\n",
              "Sex_male          bool\n",
              "Embarked_C        bool\n",
              "Embarked_Q        bool\n",
              "Embarked_S        bool\n",
              "dtype: object"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train2の各列の型を表示する\n",
        "train2.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mzOX8zXu3mzg"
      },
      "outputs": [],
      "source": [
        "# numpyのimport\n",
        "import numpy as np\n",
        "\n",
        "# train2をX_trainとY_trainに分ける\n",
        "X_train = np.array(train2.drop(columns=['Survived'])).astype('float32')\n",
        "Y_train = np.array(train2['Survived']).astype('float32')\n",
        "\n",
        "# test2のデータ全体をX_testに格納する\n",
        "X_test = np.array(test2).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qvOHvnq85GQE"
      },
      "outputs": [],
      "source": [
        "# X_trainとY_trainの3割をX_validとY_validに分割する\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtNqWIqq5LAS",
        "outputId": "e26d65fa-2a6d-48d9-b6d7-e6959d94ada0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train= (623, 11) , Y_train= (623,)\n",
            "X_valid= (268, 11) , Y_valid= (268,)\n",
            "X_test= (418, 11)\n"
          ]
        }
      ],
      "source": [
        "# 学習データと検証データ、テストデータの形状を確認\n",
        "print(\"X_train=\", X_train.shape, \", Y_train=\", Y_train.shape)\n",
        "print(\"X_valid=\", X_valid.shape, \", Y_valid=\", Y_valid.shape)\n",
        "print(\"X_test=\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lEgCdIkxUpnc"
      },
      "outputs": [],
      "source": [
        "# tensorflowのimport\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "J15nQRW5VhzI"
      },
      "outputs": [],
      "source": [
        "# モデルの構築と学習を定義する関数\n",
        "def train_model():\n",
        "    # wandbの初期設定\n",
        "    wandb.init(\n",
        "        # wandbでのプロジェクト名\n",
        "        project=\"kaggle-titanic\",\n",
        "        # wandbで記録してもらいたい設定値\n",
        "        config={\n",
        "            \"input_dense_shape\": 8,\n",
        "            \"hidden_dense_shape\": 8,\n",
        "            \"optimizer\": \"rmsprop\",\n",
        "            \"batch_size\": 32\n",
        "        })\n",
        "\n",
        "    # モデルの初期化とレイヤー定義\n",
        "    model = tf.keras.Sequential([\n",
        "        # 入力層 (Inputオブジェクトを使用)\n",
        "        tf.keras.Input(shape=(11,)),\n",
        "        tf.keras.layers.Dense(wandb.config.input_dense_shape, activation='relu'),\n",
        "        # 隠れ層\n",
        "        tf.keras.layers.Dense(wandb.config.hidden_dense_shape, activation='relu'),\n",
        "        # 出力層\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # モデルの構築\n",
        "    model.compile(optimizer=wandb.config.optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # 学習の実施\n",
        "    log = model.fit(X_train, Y_train, epochs=5000, batch_size=wandb.config.batch_size, verbose=True,\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                                min_delta=0, patience=100,\n",
        "                                                                verbose=1),\n",
        "                              wandb.keras.WandbMetricsLogger(log_freq='epoch')\n",
        "                              ],\n",
        "                    validation_data=(X_valid, Y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMQ2SOLorIoK"
      },
      "outputs": [],
      "source": [
        "# train_modelを実行する\n",
        "train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn1KQF8osoQv"
      },
      "outputs": [],
      "source": [
        "# wandbの動作を終了させる\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66LICAzsMsr8",
        "outputId": "334dcde4-e8f9-41a4-ef43-ce7e39dac58d"
      },
      "outputs": [],
      "source": [
        "# wandbでsweep（グリッドサーチ）を行なうための設定\n",
        "sweep_config = {\n",
        "    'method': 'grid',\n",
        "    'name': 'kaggle-titanic-sweep',\n",
        "    'metric': {\n",
        "        'goal': 'maximize',\n",
        "        'name': 'accuracy'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'input_dense_shape': {'values': [8, 16, 24]},\n",
        "        'hidden_dense_shape': {'values': [8, 16, 24]},\n",
        "        'optimizer': {'values': ['sgd', 'rmsprop', 'adam']},\n",
        "        'batch_size': {'values': [16, 32, 64]}\n",
        "     }\n",
        "}\n",
        "\n",
        "# sweep_configの設定値でsweepを初期化する\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project=\"kaggle-titanic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VqnYvfMQhFT"
      },
      "outputs": [],
      "source": [
        "# sweepを開始する\n",
        "wandb.agent(sweep_id, function=train_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# グリッドサーチで得た最適なパラメータ値でモデルを作り直す\n",
        "# （wandbは利用しない）\n",
        "# テストデータによる予測も行なう\n",
        "def train_model():\n",
        "    # モデルの初期化とレイヤー定義\n",
        "    model = tf.keras.Sequential([\n",
        "        # 入力層\n",
        "        tf.keras.Input(shape=(11,)),\n",
        "        tf.keras.layers.Dense(16, activation='relu'),\n",
        "        # 隠れ層\n",
        "        tf.keras.layers.Dense(16, activation='relu'),\n",
        "        # 出力層\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # モデルの構築\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # 学習の実施\n",
        "    log = model.fit(X_train, Y_train,\n",
        "                    epochs=5000,\n",
        "                    batch_size=64,\n",
        "                    verbose=True,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(\n",
        "                            monitor='val_loss',\n",
        "                            min_delta=0,\n",
        "                            patience=100,\n",
        "                            verbose=1\n",
        "                        )\n",
        "                    ],\n",
        "                    validation_data=(X_valid, Y_valid))\n",
        "\n",
        "    # テストデータによる予測\n",
        "    Y_pred_proba = model.predict(X_test)\n",
        "    Y_pred = (Y_pred_proba > 0.5).astype(\"int32\")\n",
        "\n",
        "    # Y_predを返す\n",
        "    return Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD0Uus3zzQy7",
        "outputId": "6c241daf-1cdb-46dc-c534-257138656c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 3s 431ms/step - accuracy: 0.6406 - loss: 8.30 ━━━━━━━━━━━━━━━━━━━━ 1s 17ms/step - accuracy: 0.5946 - loss: 4.5235 - val_accuracy: 0.4701 - val_loss: 1.1598\n",
            "Epoch 2/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step - accuracy: 0.3906 - loss: 1.422 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.5273 - loss: 1.0452 - val_accuracy: 0.5037 - val_loss: 1.1344\n",
            "Epoch 3/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.5000 - loss: 1.000 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - accuracy: 0.5622 - loss: 0.9239 - val_accuracy: 0.5187 - val_loss: 1.0290\n",
            "Epoch 4/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.6250 - loss: 0.758 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6359 - loss: 0.7254 - val_accuracy: 0.6119 - val_loss: 0.7659\n",
            "Epoch 5/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step - accuracy: 0.5781 - loss: 0.670 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6057 - loss: 0.7299 - val_accuracy: 0.6828 - val_loss: 0.6972\n",
            "Epoch 6/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 102ms/step - accuracy: 0.6406 - loss: 0.65 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6027 - loss: 0.7797 - val_accuracy: 0.4851 - val_loss: 0.9999\n",
            "Epoch 7/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step - accuracy: 0.4062 - loss: 1.184 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.5278 - loss: 1.1040 - val_accuracy: 0.7164 - val_loss: 0.6251\n",
            "Epoch 8/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step - accuracy: 0.6875 - loss: 0.583 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6444 - loss: 0.6612 - val_accuracy: 0.5112 - val_loss: 0.7722\n",
            "Epoch 9/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - accuracy: 0.5156 - loss: 0.828 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6073 - loss: 0.7528 - val_accuracy: 0.6530 - val_loss: 0.8662\n",
            "Epoch 10/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.6406 - loss: 0.742 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.6495 - loss: 0.6896 - val_accuracy: 0.6381 - val_loss: 0.9107\n",
            "Epoch 11/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step - accuracy: 0.5312 - loss: 0.956 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - accuracy: 0.6151 - loss: 0.7490 - val_accuracy: 0.7239 - val_loss: 0.5627\n",
            "Epoch 12/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.7031 - loss: 0.599 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6272 - loss: 0.7161 - val_accuracy: 0.4963 - val_loss: 0.8129\n",
            "Epoch 13/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - accuracy: 0.4062 - loss: 1.040 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - accuracy: 0.5810 - loss: 0.8313 - val_accuracy: 0.6791 - val_loss: 0.5957\n",
            "Epoch 14/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step - accuracy: 0.6250 - loss: 0.657 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6593 - loss: 0.6468 - val_accuracy: 0.7425 - val_loss: 0.5795\n",
            "Epoch 15/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step - accuracy: 0.7188 - loss: 0.593 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.6701 - loss: 0.658 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - accuracy: 0.6667 - loss: 0.6661 - val_accuracy: 0.6567 - val_loss: 0.7229\n",
            "Epoch 16/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.6250 - loss: 0.715 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - accuracy: 0.6681 - loss: 0.6567 - val_accuracy: 0.6754 - val_loss: 0.6030\n",
            "Epoch 17/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step - accuracy: 0.6406 - loss: 0.641 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6271 - loss: 0.7009 - val_accuracy: 0.7201 - val_loss: 0.5580\n",
            "Epoch 18/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.7812 - loss: 0.513 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.6642 - loss: 0.6829 - val_accuracy: 0.7201 - val_loss: 0.5543\n",
            "Epoch 19/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.7188 - loss: 0.522 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6933 - loss: 0.5971 - val_accuracy: 0.6716 - val_loss: 0.6287\n",
            "Epoch 20/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.6094 - loss: 0.666 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - accuracy: 0.6680 - loss: 0.6390 - val_accuracy: 0.6754 - val_loss: 0.6274\n",
            "Epoch 21/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step - accuracy: 0.6250 - loss: 0.667 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - accuracy: 0.6452 - loss: 0.6493 - val_accuracy: 0.6567 - val_loss: 0.9426\n",
            "Epoch 22/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - accuracy: 0.6250 - loss: 1.001 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.6438 - loss: 0.7562 - val_accuracy: 0.6978 - val_loss: 0.5689\n",
            "Epoch 23/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.7344 - loss: 0.566 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.7020 - loss: 0.5949 - val_accuracy: 0.6754 - val_loss: 0.7015\n",
            "Epoch 24/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.7656 - loss: 0.609 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.7215 - loss: 0.5931 - val_accuracy: 0.7239 - val_loss: 0.5522\n",
            "Epoch 25/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.7500 - loss: 0.606 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - accuracy: 0.7156 - loss: 0.6218 - val_accuracy: 0.6157 - val_loss: 0.6680\n",
            "Epoch 26/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step - accuracy: 0.5312 - loss: 0.797 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.6217 - loss: 0.7305 - val_accuracy: 0.7239 - val_loss: 0.6132\n",
            "Epoch 27/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step - accuracy: 0.6250 - loss: 0.702 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6706 - loss: 0.7147 - val_accuracy: 0.7351 - val_loss: 0.5770\n",
            "Epoch 28/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.7031 - loss: 0.589 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6818 - loss: 0.6509 - val_accuracy: 0.5261 - val_loss: 0.7312\n",
            "Epoch 29/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.5312 - loss: 0.699 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.6247 - loss: 0.6557 - val_accuracy: 0.7239 - val_loss: 0.5445\n",
            "Epoch 30/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step - accuracy: 0.7812 - loss: 0.507 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.7332 - loss: 0.5655 - val_accuracy: 0.7201 - val_loss: 0.5436\n",
            "Epoch 31/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.6562 - loss: 0.565 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6883 - loss: 0.5696 - val_accuracy: 0.6716 - val_loss: 0.6787\n",
            "Epoch 32/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step - accuracy: 0.6562 - loss: 0.632 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6886 - loss: 0.6063 - val_accuracy: 0.6828 - val_loss: 0.5936\n",
            "Epoch 33/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.6250 - loss: 0.670 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6751 - loss: 0.6459 - val_accuracy: 0.5896 - val_loss: 0.6910\n",
            "Epoch 34/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.5625 - loss: 0.723 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6735 - loss: 0.6205 - val_accuracy: 0.7164 - val_loss: 0.5549\n",
            "Epoch 35/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.6719 - loss: 0.581 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - accuracy: 0.6480 - loss: 0.7000 - val_accuracy: 0.6679 - val_loss: 0.6992\n",
            "Epoch 36/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.6562 - loss: 0.726 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.6879 - loss: 0.6460 - val_accuracy: 0.7164 - val_loss: 0.6210\n",
            "Epoch 37/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.7188 - loss: 0.516 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - accuracy: 0.7376 - loss: 0.5285 - val_accuracy: 0.6716 - val_loss: 0.7197\n",
            "Epoch 38/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - accuracy: 0.6406 - loss: 0.768 ━━━━━━━━━━━━━━━━━━━━ 0s 29ms/step - accuracy: 0.5720 - loss: 0.891 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.6074 - loss: 0.8102 - val_accuracy: 0.6828 - val_loss: 0.5948\n",
            "Epoch 39/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - accuracy: 0.7188 - loss: 0.513 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6540 - loss: 0.6391 - val_accuracy: 0.7090 - val_loss: 0.5688\n",
            "Epoch 40/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step - accuracy: 0.7500 - loss: 0.523 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6946 - loss: 0.6201 - val_accuracy: 0.7575 - val_loss: 0.5854\n",
            "Epoch 41/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - accuracy: 0.7344 - loss: 0.603 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6991 - loss: 0.5969 - val_accuracy: 0.7537 - val_loss: 0.5821\n",
            "Epoch 42/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.7188 - loss: 0.598 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.7054 - loss: 0.5919 - val_accuracy: 0.6866 - val_loss: 0.6633\n",
            "Epoch 43/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step - accuracy: 0.7031 - loss: 0.597 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6405 - loss: 0.6877 - val_accuracy: 0.7276 - val_loss: 0.5510\n",
            "Epoch 44/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.8125 - loss: 0.485 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.7429 - loss: 0.5378 - val_accuracy: 0.7313 - val_loss: 0.5403\n",
            "Epoch 45/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - accuracy: 0.7344 - loss: 0.595 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - accuracy: 0.7213 - loss: 0.5708 - val_accuracy: 0.7313 - val_loss: 0.6054\n",
            "Epoch 46/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - accuracy: 0.7031 - loss: 0.603 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.7255 - loss: 0.5670 - val_accuracy: 0.7500 - val_loss: 0.5867\n",
            "Epoch 47/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step - accuracy: 0.7812 - loss: 0.557 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.7093 - loss: 0.6354 - val_accuracy: 0.6567 - val_loss: 0.8498\n",
            "Epoch 48/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.6406 - loss: 0.766 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.7158 - loss: 0.5997 - val_accuracy: 0.6642 - val_loss: 0.7347\n",
            "Epoch 49/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - accuracy: 0.6094 - loss: 0.798 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6889 - loss: 0.6479 - val_accuracy: 0.4888 - val_loss: 0.8793\n",
            "Epoch 50/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - accuracy: 0.5781 - loss: 0.865 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.6871 - loss: 0.6461 - val_accuracy: 0.7239 - val_loss: 0.5421\n",
            "Epoch 51/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step - accuracy: 0.6875 - loss: 0.573 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - accuracy: 0.6926 - loss: 0.5922 - val_accuracy: 0.5933 - val_loss: 0.6912\n",
            "Epoch 52/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.6562 - loss: 0.676 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - accuracy: 0.6944 - loss: 0.5995 - val_accuracy: 0.6343 - val_loss: 1.0961\n",
            "Epoch 53/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step - accuracy: 0.6719 - loss: 0.848 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - accuracy: 0.7195 - loss: 0.6472 - val_accuracy: 0.6866 - val_loss: 0.6529\n",
            "Epoch 54/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step - accuracy: 0.7031 - loss: 0.574 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - accuracy: 0.6995 - loss: 0.5829 - val_accuracy: 0.6269 - val_loss: 0.6736\n",
            "Epoch 55/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - accuracy: 0.7031 - loss: 0.636 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - accuracy: 0.7366 - loss: 0.5980 - val_accuracy: 0.7015 - val_loss: 0.5824\n",
            "Epoch 56/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step - accuracy: 0.5469 - loss: 0.753 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - accuracy: 0.6212 - loss: 0.7249 - val_accuracy: 0.7463 - val_loss: 0.5850\n",
            "Epoch 57/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step - accuracy: 0.7500 - loss: 0.534 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.7488 - loss: 0.5438 - val_accuracy: 0.4963 - val_loss: 0.8759\n",
            "Epoch 58/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.4844 - loss: 0.988 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - accuracy: 0.6353 - loss: 0.7770 - val_accuracy: 0.7276 - val_loss: 0.5404\n",
            "Epoch 59/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.7656 - loss: 0.468 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step - accuracy: 0.6889 - loss: 0.6212 - val_accuracy: 0.7537 - val_loss: 0.5754\n",
            "Epoch 60/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 34ms/step - accuracy: 0.7344 - loss: 0.583 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.7203 - loss: 0.5830 - val_accuracy: 0.7500 - val_loss: 0.5529\n",
            "Epoch 61/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.6875 - loss: 0.542 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.6690 - loss: 0.6230 - val_accuracy: 0.7127 - val_loss: 0.5700\n",
            "Epoch 62/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.7812 - loss: 0.425 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7247 - loss: 0.5433 - val_accuracy: 0.7164 - val_loss: 0.6260\n",
            "Epoch 63/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.6719 - loss: 0.569 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.7129 - loss: 0.5696 - val_accuracy: 0.6642 - val_loss: 0.8352\n",
            "Epoch 64/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.5469 - loss: 0.841 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.6608 - loss: 0.6413 - val_accuracy: 0.7201 - val_loss: 0.6194\n",
            "Epoch 65/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.7344 - loss: 0.581 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - accuracy: 0.7400 - loss: 0.5715 - val_accuracy: 0.7127 - val_loss: 0.5724\n",
            "Epoch 66/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step - accuracy: 0.6719 - loss: 0.516 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step - accuracy: 0.7171 - loss: 0.525 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step - accuracy: 0.7242 - loss: 0.5620 - val_accuracy: 0.7276 - val_loss: 0.5368\n",
            "Epoch 67/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.7188 - loss: 0.490 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7487 - loss: 0.4965 - val_accuracy: 0.7201 - val_loss: 0.5331\n",
            "Epoch 68/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step - accuracy: 0.7188 - loss: 0.485 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7293 - loss: 0.5619 - val_accuracy: 0.7425 - val_loss: 0.6056\n",
            "Epoch 69/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.7031 - loss: 0.602 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.7022 - loss: 0.5821 - val_accuracy: 0.6978 - val_loss: 0.5881\n",
            "Epoch 70/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.7031 - loss: 0.467 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.7254 - loss: 0.5078 - val_accuracy: 0.5224 - val_loss: 0.8024\n",
            "Epoch 71/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - accuracy: 0.4844 - loss: 0.907 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.6662 - loss: 0.6555 - val_accuracy: 0.6940 - val_loss: 0.6017\n",
            "Epoch 72/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.7500 - loss: 0.510 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.7535 - loss: 0.5063 - val_accuracy: 0.7313 - val_loss: 0.6145\n",
            "Epoch 73/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 1s 111ms/step - accuracy: 0.7656 - loss: 0.53 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - accuracy: 0.7362 - loss: 0.5587 - val_accuracy: 0.7575 - val_loss: 0.5709\n",
            "Epoch 74/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.8125 - loss: 0.438 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7737 - loss: 0.5032 - val_accuracy: 0.7052 - val_loss: 0.5892\n",
            "Epoch 75/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 32ms/step - accuracy: 0.6875 - loss: 0.578 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7378 - loss: 0.5473 - val_accuracy: 0.5672 - val_loss: 0.7294\n",
            "Epoch 76/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.6562 - loss: 0.625 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7207 - loss: 0.5304 - val_accuracy: 0.7015 - val_loss: 0.6007\n",
            "Epoch 77/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 32ms/step - accuracy: 0.7188 - loss: 0.556 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7315 - loss: 0.5794 - val_accuracy: 0.5485 - val_loss: 0.7632\n",
            "Epoch 78/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.6406 - loss: 0.692 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.6921 - loss: 0.6165 - val_accuracy: 0.5336 - val_loss: 0.7934\n",
            "Epoch 79/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 35ms/step - accuracy: 0.6406 - loss: 0.551 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step - accuracy: 0.6986 - loss: 0.5612 - val_accuracy: 0.7463 - val_loss: 0.6093\n",
            "Epoch 80/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.7656 - loss: 0.540 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7649 - loss: 0.5036 - val_accuracy: 0.7090 - val_loss: 0.5787\n",
            "Epoch 81/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.6719 - loss: 0.630 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7065 - loss: 0.5831 - val_accuracy: 0.6194 - val_loss: 0.6936\n",
            "Epoch 82/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step - accuracy: 0.7500 - loss: 0.505 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7503 - loss: 0.5344 - val_accuracy: 0.6269 - val_loss: 0.6785\n",
            "Epoch 83/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.6719 - loss: 0.655 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7310 - loss: 0.5259 - val_accuracy: 0.7052 - val_loss: 0.5821\n",
            "Epoch 84/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.6250 - loss: 0.596 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7189 - loss: 0.5861 - val_accuracy: 0.6269 - val_loss: 0.6804\n",
            "Epoch 85/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 32ms/step - accuracy: 0.7344 - loss: 0.652 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.6858 - loss: 0.6558 - val_accuracy: 0.7313 - val_loss: 0.5380\n",
            "Epoch 86/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 1s 182ms/step - accuracy: 0.7656 - loss: 0.46 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7628 - loss: 0.4913 - val_accuracy: 0.6679 - val_loss: 0.8288\n",
            "Epoch 87/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.6406 - loss: 0.793 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7150 - loss: 0.5834 - val_accuracy: 0.7537 - val_loss: 0.5488\n",
            "Epoch 88/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.8594 - loss: 0.429 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7494 - loss: 0.5455 - val_accuracy: 0.7687 - val_loss: 0.5723\n",
            "Epoch 89/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.7812 - loss: 0.470 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7354 - loss: 0.5362 - val_accuracy: 0.7687 - val_loss: 0.5606\n",
            "Epoch 90/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step - accuracy: 0.7812 - loss: 0.550 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7407 - loss: 0.5647 - val_accuracy: 0.7612 - val_loss: 0.6046\n",
            "Epoch 91/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 30ms/step - accuracy: 0.7188 - loss: 0.611 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step - accuracy: 0.7151 - loss: 0.573 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step - accuracy: 0.7040 - loss: 0.6022 - val_accuracy: 0.7276 - val_loss: 0.5464\n",
            "Epoch 92/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.7188 - loss: 0.539 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.7557 - loss: 0.4827 - val_accuracy: 0.7351 - val_loss: 0.5553\n",
            "Epoch 93/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.7656 - loss: 0.475 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.7267 - loss: 0.5818 - val_accuracy: 0.7388 - val_loss: 0.5443\n",
            "Epoch 94/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.7500 - loss: 0.471 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7231 - loss: 0.5208 - val_accuracy: 0.6679 - val_loss: 0.7387\n",
            "Epoch 95/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.7031 - loss: 0.729 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7228 - loss: 0.5825 - val_accuracy: 0.7201 - val_loss: 0.5475\n",
            "Epoch 96/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step - accuracy: 0.7812 - loss: 0.488 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7557 - loss: 0.5157 - val_accuracy: 0.6791 - val_loss: 0.6737\n",
            "Epoch 97/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 1s 136ms/step - accuracy: 0.7188 - loss: 0.53 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - accuracy: 0.7421 - loss: 0.5291 - val_accuracy: 0.7351 - val_loss: 0.5594\n",
            "Epoch 98/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.8125 - loss: 0.492 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7497 - loss: 0.5684 - val_accuracy: 0.7313 - val_loss: 0.6427\n",
            "Epoch 99/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 32ms/step - accuracy: 0.7812 - loss: 0.542 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.7509 - loss: 0.5420 - val_accuracy: 0.7313 - val_loss: 0.5577\n",
            "Epoch 100/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.8125 - loss: 0.415 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7708 - loss: 0.4932 - val_accuracy: 0.6940 - val_loss: 0.6099\n",
            "Epoch 101/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 30ms/step - accuracy: 0.7344 - loss: 0.437 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7023 - loss: 0.6065 - val_accuracy: 0.6940 - val_loss: 0.6063\n",
            "Epoch 102/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.7500 - loss: 0.589 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7557 - loss: 0.5531 - val_accuracy: 0.7090 - val_loss: 0.5885\n",
            "Epoch 103/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step - accuracy: 0.7188 - loss: 0.533 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.6913 - loss: 0.575 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.7028 - loss: 0.5602 - val_accuracy: 0.7388 - val_loss: 0.5613\n",
            "Epoch 104/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 29ms/step - accuracy: 0.7812 - loss: 0.448 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7336 - loss: 0.5889 - val_accuracy: 0.7276 - val_loss: 0.5752\n",
            "Epoch 105/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step - accuracy: 0.7188 - loss: 0.570 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7445 - loss: 0.5388 - val_accuracy: 0.6866 - val_loss: 0.7399\n",
            "Epoch 106/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 29ms/step - accuracy: 0.7344 - loss: 0.591 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7282 - loss: 0.5889 - val_accuracy: 0.7687 - val_loss: 0.6234\n",
            "Epoch 107/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 30ms/step - accuracy: 0.7812 - loss: 0.531 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7510 - loss: 0.5127 - val_accuracy: 0.5821 - val_loss: 0.7702\n",
            "Epoch 108/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.5781 - loss: 0.710 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.6774 - loss: 0.6173 - val_accuracy: 0.6978 - val_loss: 0.6792\n",
            "Epoch 109/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 2s 270ms/step - accuracy: 0.6875 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - accuracy: 0.7502 - loss: 0.5369 - val_accuracy: 0.5634 - val_loss: 0.8029\n",
            "Epoch 110/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.5156 - loss: 0.704 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.6955 - loss: 0.5492 - val_accuracy: 0.6530 - val_loss: 0.8939\n",
            "Epoch 111/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.7031 - loss: 0.732 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.7519 - loss: 0.5382 - val_accuracy: 0.6716 - val_loss: 0.7846\n",
            "Epoch 112/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.7812 - loss: 0.447 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - accuracy: 0.7516 - loss: 0.5108 - val_accuracy: 0.6791 - val_loss: 0.6894\n",
            "Epoch 113/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.7188 - loss: 0.590 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7514 - loss: 0.5353 - val_accuracy: 0.7575 - val_loss: 0.6344\n",
            "Epoch 114/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.7344 - loss: 0.596 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7062 - loss: 0.625 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.7062 - loss: 0.6208 - val_accuracy: 0.7276 - val_loss: 0.5605\n",
            "Epoch 115/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.7031 - loss: 0.534 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7380 - loss: 0.4988 - val_accuracy: 0.6604 - val_loss: 0.8991\n",
            "Epoch 116/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.7031 - loss: 0.733 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - accuracy: 0.7202 - loss: 0.6271 - val_accuracy: 0.7724 - val_loss: 0.5544\n",
            "Epoch 117/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 35ms/step - accuracy: 0.7969 - loss: 0.448 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.7441 - loss: 0.5364 - val_accuracy: 0.7537 - val_loss: 0.5547\n",
            "Epoch 118/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.7969 - loss: 0.470 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - accuracy: 0.7814 - loss: 0.4736 - val_accuracy: 0.7649 - val_loss: 0.5702\n",
            "Epoch 119/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 29ms/step - accuracy: 0.7344 - loss: 0.503 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - accuracy: 0.7472 - loss: 0.5064 - val_accuracy: 0.6940 - val_loss: 0.6927\n",
            "Epoch 120/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 1s 145ms/step - accuracy: 0.6875 - loss: 0.71 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7359 - loss: 0.6092 - val_accuracy: 0.7761 - val_loss: 0.5851\n",
            "Epoch 121/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step - accuracy: 0.7969 - loss: 0.468 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7578 - loss: 0.4832 - val_accuracy: 0.7463 - val_loss: 0.5504\n",
            "Epoch 122/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.8750 - loss: 0.371 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7594 - loss: 0.4825 - val_accuracy: 0.6978 - val_loss: 0.6640\n",
            "Epoch 123/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 32ms/step - accuracy: 0.6875 - loss: 0.552 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7090 - loss: 0.5980 - val_accuracy: 0.6567 - val_loss: 0.9898\n",
            "Epoch 124/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.7188 - loss: 0.841 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - accuracy: 0.7310 - loss: 0.5988 - val_accuracy: 0.7500 - val_loss: 0.5500\n",
            "Epoch 125/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.7031 - loss: 0.504 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.7258 - loss: 0.5363 - val_accuracy: 0.6978 - val_loss: 0.6470\n",
            "Epoch 126/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.7188 - loss: 0.506 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7376 - loss: 0.5308 - val_accuracy: 0.7164 - val_loss: 0.5911\n",
            "Epoch 127/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 33ms/step - accuracy: 0.7344 - loss: 0.503 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.7575 - loss: 0.5124 - val_accuracy: 0.7649 - val_loss: 0.6323\n",
            "Epoch 128/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.7031 - loss: 0.666 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7492 - loss: 0.5644 - val_accuracy: 0.7500 - val_loss: 0.6536\n",
            "Epoch 129/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 33ms/step - accuracy: 0.7344 - loss: 0.565 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7827 - loss: 0.4905 - val_accuracy: 0.7052 - val_loss: 0.6895\n",
            "Epoch 130/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.6875 - loss: 0.539 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - accuracy: 0.7424 - loss: 0.5166 - val_accuracy: 0.6343 - val_loss: 0.7541\n",
            "Epoch 131/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 2s 264ms/step - accuracy: 0.6562 - loss: 0.64 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - accuracy: 0.7259 - loss: 0.5666 - val_accuracy: 0.7724 - val_loss: 0.5917\n",
            "Epoch 132/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 35ms/step - accuracy: 0.8750 - loss: 0.399 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7782 - loss: 0.4896 - val_accuracy: 0.6007 - val_loss: 0.7815\n",
            "Epoch 133/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 32ms/step - accuracy: 0.5312 - loss: 0.833 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.6751 - loss: 0.6588 - val_accuracy: 0.7015 - val_loss: 0.6337\n",
            "Epoch 134/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.7344 - loss: 0.453 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - accuracy: 0.7516 - loss: 0.4924 - val_accuracy: 0.6530 - val_loss: 0.9545\n",
            "Epoch 135/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.6562 - loss: 0.849 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7295 - loss: 0.6098 - val_accuracy: 0.7761 - val_loss: 0.5928\n",
            "Epoch 136/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 33ms/step - accuracy: 0.7656 - loss: 0.550 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.7344 - loss: 0.595 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.7069 - loss: 0.6010 - val_accuracy: 0.7687 - val_loss: 0.5628\n",
            "Epoch 137/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.6719 - loss: 0.521 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7107 - loss: 0.5347 - val_accuracy: 0.7537 - val_loss: 0.5625\n",
            "Epoch 138/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.7812 - loss: 0.495 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - accuracy: 0.7818 - loss: 0.4642 - val_accuracy: 0.7201 - val_loss: 0.5644\n",
            "Epoch 139/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.8594 - loss: 0.351 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7351 - loss: 0.5544 - val_accuracy: 0.6978 - val_loss: 0.6826\n",
            "Epoch 140/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 30ms/step - accuracy: 0.6250 - loss: 0.659 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7328 - loss: 0.5765 - val_accuracy: 0.7313 - val_loss: 0.5619\n",
            "Epoch 141/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 33ms/step - accuracy: 0.8125 - loss: 0.372 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step - accuracy: 0.7761 - loss: 0.4797 - val_accuracy: 0.7761 - val_loss: 0.6111\n",
            "Epoch 142/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.7656 - loss: 0.507 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7260 - loss: 0.6042 - val_accuracy: 0.7761 - val_loss: 0.6202\n",
            "Epoch 143/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.7031 - loss: 0.602 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - accuracy: 0.7342 - loss: 0.5644 - val_accuracy: 0.7388 - val_loss: 0.5789\n",
            "Epoch 144/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.6562 - loss: 0.655 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - accuracy: 0.7534 - loss: 0.5190 - val_accuracy: 0.7724 - val_loss: 0.5718\n",
            "Epoch 145/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 1s 161ms/step - accuracy: 0.8125 - loss: 0.46 ━━━━━━━━━━━━━━━━━━━━ 0s 33ms/step - accuracy: 0.7863 - loss: 0.4861 - val_accuracy: 0.7687 - val_loss: 0.5587\n",
            "Epoch 146/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.8594 - loss: 0.349 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step - accuracy: 0.7983 - loss: 0.4479 - val_accuracy: 0.7425 - val_loss: 0.5890\n",
            "Epoch 147/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.7656 - loss: 0.476 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - accuracy: 0.7467 - loss: 0.5346 - val_accuracy: 0.7351 - val_loss: 0.5611\n",
            "Epoch 148/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 34ms/step - accuracy: 0.9375 - loss: 0.290 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step - accuracy: 0.7901 - loss: 0.5116 - val_accuracy: 0.7388 - val_loss: 0.5672\n",
            "Epoch 149/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.8281 - loss: 0.417 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - accuracy: 0.7989 - loss: 0.4494 - val_accuracy: 0.6642 - val_loss: 0.7340\n",
            "Epoch 150/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 1s 207ms/step - accuracy: 0.6562 - loss: 0.69 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.7201 - loss: 0.5843 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step - accuracy: 0.7238 - loss: 0.5742 - val_accuracy: 0.7836 - val_loss: 0.5892\n",
            "Epoch 151/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.8750 - loss: 0.375 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step - accuracy: 0.7902 - loss: 0.4601 - val_accuracy: 0.6716 - val_loss: 0.8540\n",
            "Epoch 152/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.6875 - loss: 0.828 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - accuracy: 0.7554 - loss: 0.6031 - val_accuracy: 0.7239 - val_loss: 0.6311\n",
            "Epoch 153/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.7969 - loss: 0.553 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - accuracy: 0.7595 - loss: 0.5998 - val_accuracy: 0.7500 - val_loss: 0.5782\n",
            "Epoch 154/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.7188 - loss: 0.528 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - accuracy: 0.7701 - loss: 0.5160 - val_accuracy: 0.7127 - val_loss: 0.6889\n",
            "Epoch 155/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.7188 - loss: 0.635 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step - accuracy: 0.7345 - loss: 0.5579 - val_accuracy: 0.7500 - val_loss: 0.5946\n",
            "Epoch 156/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 1s 174ms/step - accuracy: 0.8594 - loss: 0.36 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step - accuracy: 0.7991 - loss: 0.4553 - val_accuracy: 0.4925 - val_loss: 1.1313\n",
            "Epoch 157/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 1s 111ms/step - accuracy: 0.6406 - loss: 0.85 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - accuracy: 0.7178 - loss: 0.6276 - val_accuracy: 0.7649 - val_loss: 0.5720\n",
            "Epoch 158/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.8125 - loss: 0.445 ━━━━━━━━━━━━━━━━━━━━ 0s 30ms/step - accuracy: 0.7517 - loss: 0.4983 - val_accuracy: 0.7313 - val_loss: 0.6787\n",
            "Epoch 159/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.7344 - loss: 0.620 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - accuracy: 0.7667 - loss: 0.5257 - val_accuracy: 0.7201 - val_loss: 0.6546\n",
            "Epoch 160/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.7500 - loss: 0.468 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.7750 - loss: 0.4800 - val_accuracy: 0.7687 - val_loss: 0.5698\n",
            "Epoch 161/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.7656 - loss: 0.495 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.7671 - loss: 0.5061 - val_accuracy: 0.7761 - val_loss: 0.6212\n",
            "Epoch 162/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.8594 - loss: 0.416 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - accuracy: 0.7929 - loss: 0.4702 - val_accuracy: 0.7090 - val_loss: 0.7092\n",
            "Epoch 163/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.7188 - loss: 0.576 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.7470 - loss: 0.5558 - val_accuracy: 0.7201 - val_loss: 0.6220\n",
            "Epoch 164/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.7344 - loss: 0.590 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - accuracy: 0.7642 - loss: 0.5353 - val_accuracy: 0.7425 - val_loss: 0.5688\n",
            "Epoch 165/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 1s 210ms/step - accuracy: 0.8125 - loss: 0.46 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step - accuracy: 0.7520 - loss: 0.5482 - val_accuracy: 0.7500 - val_loss: 0.5818\n",
            "Epoch 166/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.7344 - loss: 0.511 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.7659 - loss: 0.5012 - val_accuracy: 0.7500 - val_loss: 0.5817\n",
            "Epoch 167/5000\n",
            "10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.7969 - loss: 0.509 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.7543 - loss: 0.5207 - val_accuracy: 0.7239 - val_loss: 0.6753\n",
            "Epoch 167: early stopping\n",
            "14/14 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/ste ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/ste ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train_modelを実行する\n",
        "Y_pred = train_model()\n",
        "Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "H4Xe3tJj4yyz"
      },
      "outputs": [],
      "source": [
        "# X_testをDataFrameに戻し、X_test2に格納\n",
        "X_test2 = pd.DataFrame(X_test, columns=test2.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vLS47vD74EJA",
        "outputId": "289e9946-056a-473d-a44d-fd56b3e51bd1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>1305</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1306</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>1307</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>1308</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>1309</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived\n",
              "0            892         0\n",
              "1            893         0\n",
              "2            894         0\n",
              "3            895         0\n",
              "4            896         0\n",
              "..           ...       ...\n",
              "413         1305         0\n",
              "414         1306         1\n",
              "415         1307         0\n",
              "416         1308         0\n",
              "417         1309         0\n",
              "\n",
              "[418 rows x 2 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Kaggleへ提出するためのデータが入ったDataFrameを作成\n",
        "submission_data = pd.DataFrame()\n",
        "submission_data[\"PassengerId\"] = X_test2[\"PassengerId\"].astype(\"int32\")\n",
        "submission_data[\"Survived\"] = Y_pred\n",
        "submission_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SHnLQbxG60YM"
      },
      "outputs": [],
      "source": [
        "# Kaggleに提出するためのCSVファイルを作成\n",
        "submission_data.to_csv(\"my_submission_titanic.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
